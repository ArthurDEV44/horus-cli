# Devstral vs Mistral Small 3.1 : Comparaison Technique pour Horus CLI

**Date** : 2025-01-24
**Objectif** : D√©terminer le mod√®le optimal par d√©faut pour Horus CLI

---

## üìä R√©sum√© Ex√©cutif

### üèÜ Recommandation : **Devstral 24B**

**Devstral est le choix optimal** pour Horus CLI car il est :
- ‚úÖ **Sp√©cialis√© pour agents de code** (fine-tun√© de Mistral Small 3.1 sp√©cifiquement pour agentic coding)
- ‚úÖ **46.8% SWE-Bench Verified** (meilleur open-source, +20% vs GPT-4.1-mini)
- ‚úÖ **M√™me taille et contexte** (24B, 128K tokens) que Mistral Small
- ‚úÖ **Support fonction calling** (format Mistral + XML)
- ‚úÖ **Optimis√© pour exploration codebase** (cas d'usage principal d'Horus)

---

## üî¨ Comparaison D√©taill√©e

### Architecture & Sp√©cifications

| Caract√©ristique | Devstral 24B | Mistral Small 3.1 |
|----------------|--------------|-------------------|
| **Param√®tres** | 24B | 24B |
| **Context Window** | 128K tokens | 32K (3.1) / 128K (variant 22B) |
| **Base Model** | Fine-tun√© de Mistral Small 3.1 | Base |
| **Licence** | Apache 2.0 | Apache 2.0 |
| **Modalit√©s** | Text-only | Multimodal (text + vision) |
| **Tokenizer** | Tekken (131K vocab) | Tekken (131K vocab) |

**Insight cl√©** : Devstral est un **variant sp√©cialis√©** de Mistral Small 3.1, avec l'encodeur vision retir√© pour optimiser les performances coding.

---

### Benchmarks de Code

#### Traditional Coding Benchmarks

| Benchmark | Devstral 24B | Mistral Small 3.1 | Mistral Small 3.2 |
|-----------|-------------|-------------------|-------------------|
| **HumanEval** | ~88% (estim√©) | ~88% | ~93% |
| **MBPP** | ~74% (estim√©) | ~74% | ~78% |

**Note** : Devstral h√©rite des performances de Mistral Small 3.1 sur HumanEval/MBPP car fine-tun√© du m√™me base model.

#### Agentic Coding Benchmarks (Critical for Horus CLI)

| Benchmark | Devstral 24B | Mistral Small 3.1 | Comparaison |
|-----------|-------------|-------------------|-------------|
| **SWE-Bench Verified** | **46.8%** | N/A (non optimis√©) | Devstral #1 open-source |
| **SWE-Bench 1.1** | **53.6%** | N/A | +6.8% vs Devstral 1.0 |
| **vs GPT-4.1-mini** | **+20%** | N/A | Surpasse GPT-4 |
| **vs Deepseek-V3 (671B)** | **Sup√©rieur** | N/A | Bat des mod√®les 20x plus gros |

**Conclusion** : Devstral **domine** sur les t√¢ches d'agents de code (exploration codebase, multi-file editing, r√©solution d'issues GitHub).

---

### Capacit√©s Sp√©cialis√©es

#### Devstral 24B - Optimis√© pour Agentic Coding

**Forces** :
- ‚úÖ **Exploration de codebase** : Identifie relations entre composants disparates
- ‚úÖ **√âdition multi-fichiers** : Modifications coordonn√©es √† travers la codebase
- ‚úÖ **D√©tection de bugs subtils** : Analyse fonctions intriqu√©es
- ‚úÖ **R√©solution d'issues r√©elles** : Entra√Æn√© sur GitHub issues r√©els
- ‚úÖ **Fonction calling** : Support format Mistral + XML

**Use cases** :
- Software engineering agents (Horus CLI ‚úÖ)
- Codebase exploration (Horus context orchestrator ‚úÖ)
- Multi-file refactoring (TextEditorTool ‚úÖ)
- Bug fixing (VerificationPipeline ‚úÖ)

#### Mistral Small 3.1 - G√©n√©raliste avec Multimodal

**Forces** :
- ‚úÖ **Multimodal** : Text + Vision (images)
- ‚úÖ **Fonction calling rapide** : Low latency
- ‚úÖ **Multilingual** : 10+ langues
- ‚úÖ **G√©n√©raliste** : Conversational, Q&A, general knowledge
- ‚úÖ **Vitesse** : 150 tokens/sec

**Use cases** :
- Virtual assistants
- Document verification (images)
- Customer service
- Fine-tuning pour domaines sp√©cifiques (m√©dical, l√©gal)

---

### Performance Benchmarks (SWE-Bench Context)

**Test scaffold OpenHands** :

| Mod√®le | Taille | Score SWE-Bench | Note |
|--------|--------|-----------------|------|
| **Devstral 24B** | 24B | **46.8%** | üèÜ Meilleur open-source |
| Deepseek-V3 | 671B | <46.8% | Bat par Devstral |
| Qwen3 | 232B | <46.8% | Bat par Devstral |
| GPT-4.1-mini | ? | ~39% (estim√©) | -20% vs Devstral |
| Mistral Small 3.1 | 24B | N/A | Non optimis√© pour SWE-Bench |

**Source** : [Mistral AI Devstral announcement](https://mistral.ai/news/devstral)

---

### Contexte d'Utilisation Horus CLI

#### Architecture Horus : Gather-Act-Verify Loop

```
1. GATHER (ContextOrchestrator)
   - Agentic search (grep, bash, view)
   - SearchToolV2 avec scoring
   - SnippetBuilder compression

2. ACT (ToolExecutor)
   - TextEditorTool (view, create, str_replace)
   - BashTool
   - Fonction calling MCP

3. VERIFY (VerificationPipeline)
   - Lint
   - Tests
   - Type checking
```

#### Quelle capacit√© est critique ?

| Capacit√© | Importance Horus | Devstral | Mistral Small |
|----------|------------------|----------|---------------|
| **Exploration codebase** | üî• CRITIQUE | ‚úÖ Excellent | ‚ö†Ô∏è Bon |
| **Multi-file editing** | üî• CRITIQUE | ‚úÖ Excellent | ‚ö†Ô∏è Bon |
| **Fonction calling (tools)** | üî• CRITIQUE | ‚úÖ Oui | ‚úÖ Oui |
| **Context window long** | üî• CRITIQUE | ‚úÖ 128K | ‚ö†Ô∏è 32K (3.1) |
| **Code generation** | üü° Important | ‚úÖ 88% HumanEval | ‚úÖ 88% HumanEval |
| **Multimodal (images)** | ‚ùå Non requis | ‚ùå Non | ‚úÖ Oui |
| **Conversational** | üü¢ Nice-to-have | ‚úÖ Oui | ‚úÖ Oui |

**Conclusion** : Devstral **couvre toutes les capacit√©s critiques** d'Horus CLI, avec performance sup√©rieure sur exploration codebase.

---

### Ressources Syst√®me

| M√©trique | Devstral 24B | Mistral Small 3.1 |
|----------|-------------|-------------------|
| **VRAM minimum** | 32-40 GB | 12-16 GB (3.1) / 32-40 GB (22B) |
| **RAM (sans GPU)** | 32 GB | 32 GB |
| **Hardware requis** | RTX 4090 ou Mac 32GB | RTX 3090 ou Mac 16GB (3.1) |

**Note** : Devstral a les **m√™mes** exigences que Mistral Small 22B (128K variant), car m√™me taille (24B).

---

### Disponibilit√© & Deployment

| Plateforme | Devstral 24B | Mistral Small 3.1 |
|------------|-------------|-------------------|
| **Ollama** | ‚úÖ `ollama run devstral` | ‚úÖ `ollama run mistral-small` |
| **HuggingFace** | ‚úÖ mistralai/Devstral-Small-2507 | ‚úÖ mistralai/Mistral-Small-3.1 |
| **API Mistral** | ‚úÖ $0.1/M input, $0.3/M output | ‚úÖ $0.1/M input, $0.3/M output |
| **LM Studio** | ‚úÖ | ‚úÖ |
| **Local** | ‚úÖ 100% priv√© | ‚úÖ 100% priv√© |

**Pricing** : Identique (m√™me base model).

---

## üéØ Recommandation pour Horus CLI

### Choix Optimal : **Devstral 24B**

**Justification** :

1. **Sp√©cialis√© pour Horus use case** ‚úÖ
   - Exploration codebase = phase GATHER
   - Multi-file editing = TextEditorTool
   - Agent workflows = boucle gather-act-verify

2. **Performance sup√©rieure mesur√©e** ‚úÖ
   - 46.8% SWE-Bench (meilleur open-source)
   - Bat GPT-4.1-mini de 20%
   - Surpasse mod√®les 20x plus gros

3. **M√™me co√ªt compute** ‚úÖ
   - 24B param√®tres (identique Mistral Small)
   - 128K context (identique variant 22B)
   - Ollama support identique

4. **Fine-tun√© du meilleur g√©n√©raliste** ‚úÖ
   - Base = Mistral Small 3.1 (88% HumanEval)
   - H√©rite des capacit√©s g√©n√©rales
   - Sp√©cialis√© en + pour coding agents

5. **Context window maximal** ‚úÖ
   - 128K tokens (vs 32K Mistral Small 3.1)
   - Critique pour large codebases
   - Permet phase GATHER plus profonde

**Trade-offs acceptables** :
- ‚ùå Pas de multimodal (vision) ‚Üí Horus n'en a pas besoin
- ‚ùå Peut-√™tre l√©g√®rement plus lent en chat conversationnel ‚Üí Horus focus sur coding tasks

---

### Configuration Recommand√©e

#### Default Settings Update

**Fichier** : `src/utils/settings-manager.ts`

```typescript
const DEFAULT_USER_SETTINGS: Partial<UserSettings> = {
  baseURL: "http://localhost:11434/v1",
  defaultModel: "devstral", // ‚úÖ UPDATED (was "mistral-small")
  models: [
    "mistral",        // Fast (7B, 8K)
    "mistral-small",  // Balanced g√©n√©raliste (22B, 32K)
    "devstral",       // üèÜ RECOMMENDED for coding (24B, 128K)
    "mixtral",        // Powerful multi-task (8x7B, 32K)
    "deepseek-coder-v2:16b",
    "qwen2.5-coder:14b",
  ],
};

const DEFAULT_PROJECT_SETTINGS: Partial<ProjectSettings> = {
  model: "devstral", // ‚úÖ UPDATED (was "mistral-small")
};
```

**Fichier** : `src/horus/client.ts`

```typescript
export class HorusClient {
  private currentModel: string = "devstral"; // ‚úÖ UPDATED (was "devstral:24b")
  // ...
}
```

#### Model Selector Update

**Fichier** : `src/horus/model-selector.ts`

```typescript
export const MISTRAL_MODELS = {
  mistral: {
    name: 'mistral',
    vramMin: 4,
    context: 8192,
    speed: 3,
    quality: 2,
  },
  'mistral-small': {
    name: 'mistral-small',
    vramMin: 12,
    context: 32768,
    speed: 2,
    quality: 3,
  },
  'devstral': { // ‚úÖ ADDED
    name: 'devstral',
    vramMin: 32,
    context: 131072, // 128K
    speed: 2,
    quality: 4, // Meilleur pour coding
  },
  'mixtral': {
    name: 'mixtral',
    vramMin: 24,
    context: 32768,
    speed: 1,
    quality: 4,
  },
};

export const MODEL_PROFILES: Record<string, string> = {
  fast: 'mistral',
  balanced: 'mistral-small', // G√©n√©raliste
  powerful: 'devstral', // ‚úÖ UPDATED (was 'mixtral') - Best for coding
  deep: 'devstral', // ‚úÖ UPDATED (was 'devstral:24b') - Max context
};
```

---

### Migration Path

**Step 1** : Update default model
```typescript
// DEFAULT_USER_SETTINGS.defaultModel
"mistral-small" ‚Üí "devstral"
```

**Step 2** : Update HorusClient default
```typescript
// HorusClient.currentModel
"devstral:24b" ‚Üí "devstral"
```

**Step 3** : Update model-selector profiles
```typescript
// MODEL_PROFILES
powerful: "mixtral" ‚Üí "devstral"
deep: "devstral:24b" ‚Üí "devstral"
```

**Step 4** : Update documentation
- README.md : Mention Devstral comme recommand√©
- CLAUDE.md : Update default model references
- docs/model-selection.md : Add Devstral comparison section

---

## üìö Sources

### Documentation Officielle
- [Ollama Devstral](https://ollama.com/library/devstral)
- [Ollama Mistral Small](https://ollama.com/library/mistral-small)
- [Mistral AI - Devstral Announcement](https://mistral.ai/fr/news/devstral)
- [Mistral AI - Mistral Small 3.1 Announcement](https://mistral.ai/fr/news/mistral-small-3-1)

### Research & Benchmarks
- [Mistral AI - Devstral 2507 Upgrade](https://mistral.ai/news/devstral-2507)
- [AI Native Dev - Devstral Analysis](https://ainativedev.io/news/devstral)
- [Devstral SWE-Bench Results](https://adam.holter.com/devstral-small-2507-mistral-ais-agentic-coding-llm-just-destroyed-the-swe-bench/)
- [Mistral Small 3.1 vs Devstral Comparison](https://model.aibase.com/compare/mistral-small-3.1-vs-devstral-small)

### Community & Comparisons
- [Magistral vs Devstral vs DeepSeek R1](https://blog.getbind.co/2025/07/20/magistral-vs-devstral-vs-deepseek-r1-which-is-best/)
- [Mistral Small 3.2 Benchmarks](https://openlaboratory.ai/models/mistral-small-3_2-24b-instruct-2506)

---

## üîÑ Next Steps

1. ‚úÖ **Update default model** dans settings-manager.ts
2. ‚úÖ **Update HorusClient** default model
3. ‚úÖ **Update model-selector** profiles (powerful/deep)
4. üìù **Update documentation** (README, CLAUDE.md)
5. üß™ **Test Devstral** avec prompts Horus typiques
6. üìä **Capture benchmarks** avec Devstral vs Mistral Small

---

**Conclusion Finale** : Devstral est le choix **objectivement sup√©rieur** pour Horus CLI car sp√©cialement con√ßu pour les agents de code, avec performances SWE-Bench prouv√©es et m√™me co√ªt compute que Mistral Small.
